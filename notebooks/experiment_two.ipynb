{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "### In this experiment we compare different metamodels on an image completion task framed as a 2D regression task \n",
    "We compare the amortised GI BNN with a convolutional conditional neural process and an amortised MFVI BNN as two baseline models. The models will be evaluated on datasets which will be treated as metadatasets in which each image will be subsampled and treated as a 2D regression dataset. The following datasets will be considered:\n",
    "- MNIST\n",
    "- CelebA, including an out-of-distribution qualitative evaluation on the Ellen Oscars Selfie\n",
    "- CIFAR10\n",
    "\n",
    "For each test case, a linear interpolator will be used as a lower benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import wbml.experiment\n",
    "import wbml.plot\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import bnn_amort_inf\n",
    "from bnn_amort_inf.models.likelihoods.normal import (\n",
    "    NormalLikelihood,\n",
    "    BernoulliLikelihood,\n",
    ")\n",
    "from bnn_amort_inf.models.bnn import gibnn, mfvi_bnn\n",
    "from bnn_amort_inf.models.np import GridConvCNP, CNP\n",
    "from bnn_amort_inf import utils\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = wbml.experiment.WorkingDirectory(\"./experiment_two\", log=None, override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data and Generate Metadatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 100  # note cannot be greater than 9000\n",
    "meta_datasets = {}\n",
    "ratio = 0.25  # proportion of context pixels in training images\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=wd.root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "mnist_iter = iter(torch.utils.data.DataLoader(mnist, shuffle=True))\n",
    "img_samp = next(mnist_iter)[0]\n",
    "\n",
    "I, M_c = (\n",
    "    next(mnist_iter)[0].squeeze(0),\n",
    "    utils.dataset_utils.random_mask(ratio, img_samp)[1],\n",
    ")\n",
    "\n",
    "m_d = []\n",
    "for _ in range(num_datasets):\n",
    "    img = next(mnist_iter)[0].squeeze(0)\n",
    "\n",
    "    # Convert to binary.\n",
    "    img = img.round()\n",
    "\n",
    "    mask = utils.dataset_utils.random_mask(ratio, img_samp)[1]\n",
    "    x_c, y_c, x_t, y_t = utils.dataset_utils.img_for_reg(img, mask)\n",
    "    m_d.append((img, mask, x_c, y_c, x_t, y_t))\n",
    "\n",
    "meta_datasets[\"mnist\"] = utils.dataset_utils.MetaDataset(m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(meta_datasets[\"mnist\"].datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convcnp = GridConvCNP(\n",
    "#     x_dim=2,\n",
    "#     y_dim=1,\n",
    "#     embedded_dim=2,\n",
    "#     cnn_chans=[128, 128, 128],\n",
    "#     conv_kernel_size=5,\n",
    "#     cnn_kernel_size=3,\n",
    "#     res=True,\n",
    "# )\n",
    "\n",
    "# convcnp_tracker = utils.training_utils.train_metamodel(\n",
    "#     convcnp,\n",
    "#     meta_datasets[\"mnist\"],\n",
    "#     image=True,\n",
    "#     gridconv=True,\n",
    "#     lr=1e-4,\n",
    "#     max_iters=5_000,\n",
    "#     batch_size=16,\n",
    "#     min_es_iters=150,\n",
    "#     ref_es_iters=50,\n",
    "#     smooth_es_iters=50,\n",
    "#     es=True,\n",
    "#     man_thresh=(\n",
    "#         \"ll\",\n",
    "#         2000.0,\n",
    "#     ),  # manual threshold that only stops training loop if ll>man_thresh... very hacky but fine for now\n",
    "# )\n",
    "\n",
    "# if plot_training_metrics:\n",
    "#     fig, axes = plt.subplots(\n",
    "#         len(convcnp_tracker.keys()),\n",
    "#         1,\n",
    "#         figsize=(8, len(convcnp_tracker.keys()) * 4),\n",
    "#         dpi=100,\n",
    "#         sharex=True,\n",
    "#     )\n",
    "\n",
    "#     for ax, (key, vals) in zip(axes, convcnp_tracker.items()):\n",
    "#         ax.plot(vals)\n",
    "#         ax.set_ylabel(key)\n",
    "#         ax.grid()\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agibnn = gibnn.AmortisedGIBNN(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    hidden_dims=[20, 20],\n",
    "    in_hidden_dims=[50, 50],\n",
    "    np_kl=False,\n",
    "    likelihood=BernoulliLikelihood(),\n",
    ")\n",
    "\n",
    "agibnn_tracker = utils.training_utils.train_metamodel(\n",
    "    agibnn,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    image=True,\n",
    "    np_loss=True,\n",
    "    lr=1e-3,\n",
    "    max_iters=10_000,\n",
    "    batch_size=1,\n",
    "    min_es_iters=50,\n",
    "    ref_es_iters=30,\n",
    "    smooth_es_iters=10,\n",
    "    es=False,\n",
    "    # man_thresh=(\"elbo\", -2.0e10),\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(agibnn_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(agibnn_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, agibnn_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 4\n",
    "num_models = 1\n",
    "test_datasets = []\n",
    "for _ in range(num_test):\n",
    "    img = next(mnist_iter)[0].squeeze(0)\n",
    "    img = img.round()\n",
    "    mask = utils.dataset_utils.random_mask(0.25, img_samp)[1]\n",
    "    x_c, y_c, x_t, y_t = utils.dataset_utils.img_for_reg(img, mask)\n",
    "    test_datasets.append((img, mask, x_c, y_c, x_t, y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_std = True\n",
    "\n",
    "for dataset in test_datasets:\n",
    "    I, M_c, x_c, y_c, x_t, y_t = dataset\n",
    "    ctx_img = utils.dataset_utils.vis_ctxt_img(M_c, I)\n",
    "    # convcnp_preds = convcnp(I, M_c)\n",
    "    # convcnp_pred_img = convcnp_preds.loc.detach().permute(1, 2, 0).numpy()\n",
    "    # convcnp_pred_std = convcnp_preds.scale.detach().permute(1, 2, 0).numpy()\n",
    "    preds = agibnn(x_c, y_c, x_test=x_t, num_samples=10)[-1]\n",
    "    # agibnn_pred_img, agibnn_pred_std = utils.dataset_utils.samps_to_img_dist(\n",
    "    #     agibnn_preds\n",
    "    # )\n",
    "\n",
    "    pred_dists = agibnn.likelihood(preds)\n",
    "    pred_probs = pred_dists.probs.detach()\n",
    "    pred_img = pred_probs.mean(0).reshape((28, 28, 1))\n",
    "    pred_std = pred_probs.std(0).reshape((28, 28, 1))\n",
    "\n",
    "    num_plots = 2 + num_models * (1 + int(plot_std))\n",
    "    fig, axes = plt.subplots(1, num_plots)\n",
    "    axes[0].imshow(I.permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
    "    axes[0].axis(False)\n",
    "    axes[1].imshow(ctx_img)\n",
    "    axes[1].axis(False)\n",
    "    axes[2].imshow(pred_img, cmap=\"gray\")\n",
    "    axes[2].axis(False)\n",
    "    if plot_std:\n",
    "        axes[3].imshow(pred_std, cmap=\"viridis\")\n",
    "        axes[3].axis(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "35fb1e0ce207c8143d1ac09f84e572577d5a384bc00c7057b27c48465068398e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
