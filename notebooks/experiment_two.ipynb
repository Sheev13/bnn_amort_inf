{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "### In this experiment we compare different metamodels on an image completion task framed as a 2D regression task \n",
    "We compare the amortised GI BNN with a convolutional conditional neural process and an amortised MFVI BNN as two baseline models. The models will be evaluated on datasets which will be treated as metadatasets in which each image will be subsampled and treated as a 2D regression dataset. The following datasets will be considered:\n",
    "- MNIST\n",
    "- CelebA, including an out-of-distribution qualitative evaluation on the Ellen Oscars Selfie\n",
    "- CIFAR10\n",
    "\n",
    "For each test case, a linear interpolator will be used as a lower benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from bnn_amort_inf.models.bnn import gibnn, mfvi_bnn\n",
    "from bnn_amort_inf.models.np import GridConvCNP, CNP\n",
    "from bnn_amort_inf import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data and Generate Metadatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 1000  # note cannot be greater than 9000\n",
    "meta_datasets = {}\n",
    "ratio = 0.5  # proportion of context pixels in training images\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "mnist_iter = iter(torch.utils.data.DataLoader(mnist, shuffle=True))\n",
    "img_samp = next(mnist_iter)[0]\n",
    "\n",
    "I, M_c = (\n",
    "    next(mnist_iter)[0].squeeze(0),\n",
    "    utils.dataset_utils.random_mask(ratio, img_samp)[1],\n",
    ")\n",
    "\n",
    "meta_datasets[\"mnist\"] = utils.dataset_utils.MetaDataset(\n",
    "    [\n",
    "        (\n",
    "            next(mnist_iter)[0].squeeze(0),\n",
    "            utils.dataset_utils.random_mask(ratio, img_samp)[1],\n",
    "        )\n",
    "        for _ in range(num_datasets)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetconvcnp = GridConvCNP(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    embedded_dim=128,\n",
    "    conv_kernel_size=5,\n",
    "    cnn_kernel_size=3,\n",
    "    unet=True,\n",
    "    num_unet_layers=6,  # 2**((num_unet_layers / 2) - 1) must divide image width (/height) in pixels\n",
    "    unet_starting_chans=64,\n",
    "    pool=\"max\",\n",
    "    target_only_loss=False,  # only the pixels not in context set are used in loss if True\n",
    ")\n",
    "\n",
    "unetconvcnp_tracker = utils.training_utils.train_metamodel(\n",
    "    unetconvcnp,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    gridconv=True,\n",
    "    lr=2e-4,\n",
    "    max_iters=5_000,\n",
    "    batch_size=16,\n",
    "    min_es_iters=150,\n",
    "    ref_es_iters=50,\n",
    "    smooth_es_iters=50,\n",
    "    es=True,\n",
    "    man_thresh=1600,  # manual threshold that only stops training loop if ll>man_thresh... very hacky but fine for now\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(unetconvcnp_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(unetconvcnp_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, unetconvcnp_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resconvcnp = GridConvCNP(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    embedded_dim=128,\n",
    "    cnn_chans=[128, 128, 128],\n",
    "    conv_kernel_size=5,\n",
    "    cnn_kernel_size=3,\n",
    "    res=True,\n",
    ")\n",
    "\n",
    "resconvcnp_tracker = utils.training_utils.train_metamodel(\n",
    "    resconvcnp,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    gridconv=True,\n",
    "    lr=2e-4,\n",
    "    max_iters=5_000,\n",
    "    batch_size=16,\n",
    "    min_es_iters=150,\n",
    "    ref_es_iters=50,\n",
    "    smooth_es_iters=50,\n",
    "    es=True,\n",
    "    man_thresh=1600,  # manual threshold that only stops training loop if ll>man_thresh... very hacky but fine for now\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(resconvcnp_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(resconvcnp_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, resconvcnp_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 4\n",
    "num_models = 2\n",
    "test_datasets = [\n",
    "    (\n",
    "        next(mnist_iter)[0].squeeze(0),\n",
    "        utils.dataset_utils.random_mask(0.2, img_samp)[1],\n",
    "    )\n",
    "    for _ in range(num_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_std = True\n",
    "\n",
    "for dataset in test_datasets:\n",
    "    I, M_c = dataset\n",
    "    ctx_img = utils.dataset_utils.vis_ctxt_img(M_c, I)\n",
    "    unet_preds = unetconvcnp(I, M_c)\n",
    "    res_preds = resconvcnp(I, M_c)\n",
    "    unet_pred_img = unet_preds.loc.detach().permute(1, 2, 0).numpy()\n",
    "    unet_pred_std = unet_preds.scale.detach().permute(1, 2, 0).numpy()\n",
    "    res_pred_img = res_preds.loc.detach().permute(1, 2, 0).numpy()\n",
    "    res_pred_std = res_preds.scale.detach().permute(1, 2, 0).numpy()\n",
    "    num_plots = 2 + num_models * (1 + int(plot_std))\n",
    "    fig, axes = plt.subplots(1, num_plots)\n",
    "    axes[0].imshow(I.permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
    "    axes[0].axis(False)\n",
    "    axes[1].imshow(ctx_img)\n",
    "    axes[1].axis(False)\n",
    "    axes[2].imshow(unet_pred_img, cmap=\"gray\")\n",
    "    axes[2].axis(False)\n",
    "    if plot_std:\n",
    "        axes[3].imshow(unet_pred_std, cmap=\"viridis\")\n",
    "        axes[3].axis(False)\n",
    "        axes[4].imshow(res_pred_img, cmap=\"gray\")\n",
    "        axes[4].axis(False)\n",
    "        axes[5].imshow(res_pred_std, cmap=\"viridis\")\n",
    "        axes[5].axis(False)\n",
    "    else:\n",
    "        axes[3].imshow(res_pred_img, cmap=\"gray\")\n",
    "        axes[3].axis(False)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn-amort-inf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "35fb1e0ce207c8143d1ac09f84e572577d5a384bc00c7057b27c48465068398e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
