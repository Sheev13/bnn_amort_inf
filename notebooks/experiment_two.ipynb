{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "### In this experiment we compare different metamodels on an image completion task framed as a 2D regression task \n",
    "We compare the amortised GI BNN with a convolutional conditional neural process and an amortised MFVI BNN as two baseline models. The models will be evaluated on datasets which will be treated as metadatasets in which each image will be subsampled and treated as a 2D regression dataset. The following datasets will be considered:\n",
    "- MNIST\n",
    "- CelebA, including an out-of-distribution qualitative evaluation on the Ellen Oscars Selfie\n",
    "- CIFAR10\n",
    "\n",
    "For each test case, a linear interpolator will be used as a lower benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.auto as tqdm\n",
    "import sys\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from bnn_amort_inf.models.bnn import gibnn, mfvi_bnn\n",
    "from bnn_amort_inf.models.np import GridConvCNP, CNP\n",
    "from bnn_amort_inf import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data and Generate Metadatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 200  # note cannot be greater than 9000\n",
    "meta_datasets = {}\n",
    "ratio = 0.1  # proportion of context pixels in image\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "mnist_iter = iter(torch.utils.data.DataLoader(mnist, shuffle=True))\n",
    "img_samp = next(mnist_iter)[0]\n",
    "\n",
    "I, M_c = (\n",
    "    next(mnist_iter)[0].squeeze(0),\n",
    "    utils.dataset_utils.random_mask(ratio, img_samp)[1],\n",
    ")\n",
    "\n",
    "meta_datasets[\"mnist\"] = utils.dataset_utils.MetaDataset(\n",
    "    [\n",
    "        (\n",
    "            next(mnist_iter)[0].squeeze(0),\n",
    "            utils.dataset_utils.random_mask(ratio, img_samp)[1],\n",
    "        )\n",
    "        for _ in range(num_datasets)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convcnp = GridConvCNP(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    embedded_dim=64,\n",
    "    cnn_chans=[64, 64],\n",
    "    kernel_size=9,\n",
    ")\n",
    "\n",
    "convcnp_tracker = utils.training_utils.train_metamodel(\n",
    "    convcnp,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    gridconv=True,\n",
    "    lr=1e-3,\n",
    "    max_iters=50_000,\n",
    "    batch_size=10,\n",
    "    min_es_iters=10_000,\n",
    "    ref_es_iters=1_000,\n",
    "    smooth_es_iters=500,\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(convcnp_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(convcnp_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, convcnp_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn-amort-inf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "35fb1e0ce207c8143d1ac09f84e572577d5a384bc00c7057b27c48465068398e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
