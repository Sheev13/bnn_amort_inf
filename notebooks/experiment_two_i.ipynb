{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "### In this experiment we compare different metamodels on an image completion task framed as a 2D regression task \n",
    "We compare the amortised GI BNN with a convolutional conditional neural process and an amortised MFVI BNN as two baseline models. The models will be evaluated on datasets which will be treated as metadatasets in which each image will be subsampled and treated as a 2D regression dataset. The following datasets will be considered:\n",
    "- MNIST\n",
    "- CelebA, including an out-of-distribution qualitative evaluation on the Ellen Oscars Selfie\n",
    "- CIFAR10\n",
    "\n",
    "For each test case, a linear interpolator will be used as a lower benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import wbml.experiment\n",
    "import wbml.plot\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import bnn_amort_inf\n",
    "from bnn_amort_inf.models.likelihoods.normal import (\n",
    "    NormalLikelihood,\n",
    "    HeteroscedasticNormalLikelihood,\n",
    ")\n",
    "from bnn_amort_inf.models.likelihoods.bernoulli import BernoulliLikelihood\n",
    "from bnn_amort_inf.models.bnn import gibnn, mfvi_bnn\n",
    "from bnn_amort_inf.models.np.convcnp import GridConvCNP\n",
    "from bnn_amort_inf import utils\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd = wbml.experiment.WorkingDirectory(\"./experiment_two\", log=None, override=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data and Generate Metadatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_datasets = 9000  # note cannot be greater than 9000\n",
    "meta_datasets = {}\n",
    "ratio = 0.25  # proportion of context pixels in training images\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=wd.root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "mnist_iter = iter(torch.utils.data.DataLoader(mnist, shuffle=True))\n",
    "\n",
    "m_d = []\n",
    "for _ in range(num_datasets):\n",
    "    img = next(mnist_iter)[0].squeeze(0)\n",
    "\n",
    "    # Convert to binary.\n",
    "    bin_img = img.round()\n",
    "    mask = utils.dataset_utils.random_mask(ratio, img)[1]\n",
    "    m_d.append((img, bin_img, mask))\n",
    "\n",
    "meta_datasets[\"mnist\"] = utils.dataset_utils.MetaDataset(m_d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_training_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convcnp_lik = BernoulliLikelihood()\n",
    "\n",
    "convcnp = GridConvCNP(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    embedded_dim=256,\n",
    "    cnn_chans=[128, 128, 128],\n",
    "    conv_kernel_size=5,\n",
    "    cnn_kernel_size=3,\n",
    "    res=True,\n",
    "    likelihood=convcnp_lik,\n",
    ")\n",
    "\n",
    "convcnp_tracker = utils.training_utils.train_metamodel(\n",
    "    convcnp,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    image=True,\n",
    "    gridconv=True,\n",
    "    lr=5e-4,\n",
    "    max_iters=5_000,\n",
    "    batch_size=12,\n",
    "    min_es_iters=1000,\n",
    "    ref_es_iters=400,\n",
    "    smooth_es_iters=100,\n",
    "    es=True,\n",
    "    # man_thresh=(\n",
    "    #     \"ll\",\n",
    "    #     2000.0,\n",
    "    # ),  # manual threshold that only stops training loop if ll>man_thresh... very hacky but fine for now\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(convcnp_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(convcnp_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, convcnp_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agibnn_lik = BernoulliLikelihood()\n",
    "\n",
    "agibnn = gibnn.AmortisedGIBNN(\n",
    "    x_dim=2,\n",
    "    y_dim=1,\n",
    "    hidden_dims=[64, 64],\n",
    "    in_hidden_dims=[100, 100],\n",
    "    likelihood=agibnn_lik,\n",
    ")\n",
    "\n",
    "agibnn_tracker = utils.training_utils.train_metamodel(\n",
    "    agibnn,\n",
    "    meta_datasets[\"mnist\"],\n",
    "    image=True,\n",
    "    loss_fn=\"npml_loss\",  # options are \"npml_loss\", \"npvi_loss\", \"loss\"\n",
    "    lr=1e-3,\n",
    "    max_iters=10_000,\n",
    "    batch_size=3,\n",
    "    min_es_iters=500,\n",
    "    ref_es_iters=200,\n",
    "    smooth_es_iters=100,\n",
    "    es=True,\n",
    "    # man_thresh=(\"elbo\", -160),\n",
    ")\n",
    "\n",
    "if plot_training_metrics:\n",
    "    fig, axes = plt.subplots(\n",
    "        len(agibnn_tracker.keys()),\n",
    "        1,\n",
    "        figsize=(8, len(agibnn_tracker.keys()) * 4),\n",
    "        dpi=100,\n",
    "        sharex=True,\n",
    "    )\n",
    "\n",
    "    for ax, (key, vals) in zip(axes, agibnn_tracker.items()):\n",
    "        ax.plot(vals)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 5\n",
    "test_datasets = []\n",
    "for _ in range(num_test):\n",
    "    img = next(mnist_iter)[0].squeeze(0)\n",
    "    bin_img = img.round()\n",
    "    mask = utils.dataset_utils.random_mask(0.25, img)[1]\n",
    "    test_datasets.append((img, bin_img, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_std = True\n",
    "round_preds = False\n",
    "round_orig_img = False\n",
    "\n",
    "for dataset in test_datasets:\n",
    "    img, bin_img, mask = dataset\n",
    "    x_c, y_c, x_t, y_t = utils.dataset_utils.img_for_reg(bin_img, mask)\n",
    "    ctx_img = utils.dataset_utils.vis_ctxt_img(mask, bin_img)\n",
    "    convcnp_preds = convcnp(bin_img, mask)\n",
    "    if isinstance(convcnp_lik, BernoulliLikelihood):\n",
    "        a = convcnp_preds.sample(torch.Size([2]))\n",
    "        convcnp_pred_samps = convcnp_preds.sample(\n",
    "            sample_shape=torch.Size([1000])\n",
    "        ).detach()\n",
    "        convcnp_pred_img = convcnp_pred_samps.mean(0).reshape((28, 28, 1))\n",
    "        convcnp_pred_std = convcnp_pred_samps.std(0).reshape((28, 28, 1))\n",
    "    else:\n",
    "        convcnp_pred_img = convcnp_preds.loc.detach().reshape((28, 28, 1)).numpy()\n",
    "        convcnp_pred_std = convcnp_preds.scale.detach().reshape((28, 28, 1)).numpy()\n",
    "\n",
    "    x_test = utils.dataset_utils.test_grid(img.shape[-2:])\n",
    "\n",
    "    preds = agibnn(x_c, y_c, x_test=x_test, num_samples=10)[-1]\n",
    "    pred_dists = agibnn.likelihood(preds)\n",
    "    if isinstance(agibnn_lik, BernoulliLikelihood):\n",
    "        pred_probs = pred_dists.probs.detach()\n",
    "        pred_img = pred_probs.mean(0).reshape((28, 28, 1))\n",
    "        pred_std = pred_probs.std(0).reshape((28, 28, 1))\n",
    "    else:\n",
    "        pred_probs = pred_dists.mean.detach()\n",
    "        pred_img = pred_probs.mean(0).reshape((28, 28, 1))\n",
    "        pred_std = pred_probs.std(0).reshape((28, 28, 1))\n",
    "\n",
    "    if round_preds:\n",
    "        pred_img = pred_img.round()\n",
    "        convcnp_pred_img = convcnp_pred_img.round()\n",
    "    if round_orig_img:\n",
    "        img = img.round()\n",
    "\n",
    "    num_plots = 2 + 2 * (1 + int(plot_std))\n",
    "    fig, axes = plt.subplots(1, num_plots)\n",
    "    axes[0].imshow(img.permute(1, 2, 0).numpy(), cmap=\"gray\")\n",
    "    axes[0].axis(False)\n",
    "    axes[1].imshow(ctx_img)\n",
    "    axes[1].axis(False)\n",
    "    axes[2].imshow(pred_img, cmap=\"gray\")\n",
    "    axes[2].axis(False)\n",
    "    if plot_std:\n",
    "        axes[3].imshow(pred_std, cmap=\"viridis\")\n",
    "        axes[3].axis(False)\n",
    "        axes[4].imshow(convcnp_pred_img, cmap=\"gray\")\n",
    "        axes[4].axis(False)\n",
    "        axes[5].imshow(convcnp_pred_std, cmap=\"viridis\")\n",
    "        axes[5].axis(False)\n",
    "    else:\n",
    "        axes[3].imshow(convcnp_pred_img, cmap=\"gray\")\n",
    "        axes[3].axis(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvCNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "# import sys\n",
    "\n",
    "# sys.path.append(\"../../Neural-Process-Family\")\n",
    "\n",
    "# from npf import ConvCNP, GridConvCNP, CNPFLoss\n",
    "# from npf.architectures import CNN, MLP, ResConvBlock, SetConv, discard_ith_arg\n",
    "# from npf.utils.helpers import CircularPad2d, make_abs_conv, make_padded_conv\n",
    "# from utils.ntbks_helpers import get_img_datasets\n",
    "# from utils.helpers import count_parameters\n",
    "# from utils.data import cntxt_trgt_collate, get_test_upscale_factor\n",
    "# from npf.utils.datasplit import GridCntxtTrgtGetter, RandomMasker, no_masker\n",
    "\n",
    "# img_datasets, img_test_datasets = get_img_datasets([\"mnist\"])\n",
    "\n",
    "# # Random masker, masking between 0% and 30% of input points.\n",
    "# get_cntxt_trgt_2d = cntxt_trgt_collate(\n",
    "#     GridCntxtTrgtGetter(\n",
    "#         context_masker=RandomMasker(a=0.0, b=0.3),\n",
    "#         target_masker=no_masker,\n",
    "#     ),\n",
    "#     is_return_masks=True,  # will be using grid conv CNP => can work directly with mask\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# r_dim = 32\n",
    "# model_kwargs = dict(\n",
    "#     r_dim=r_dim,\n",
    "#     Decoder=discard_ith_arg(  # disregards the target features to be translation equivariant\n",
    "#         partial(MLP, n_hidden_layers=4, hidden_size=r_dim), i=0\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "# cnn_kwargs = dict(\n",
    "#     ConvBlock=ResConvBlock,\n",
    "#     is_chan_last=True,  # all computations are done with channel last in our code\n",
    "#     n_conv_layers=2,  # layers per block\n",
    "# )\n",
    "\n",
    "\n",
    "# # on the grid\n",
    "# model_2d = partial(\n",
    "#     GridConvCNP,\n",
    "#     x_dim=1,  # for gridded conv it's the mask shape\n",
    "#     CNN=partial(\n",
    "#         CNN,\n",
    "#         Conv=torch.nn.Conv2d,\n",
    "#         Normalization=torch.nn.BatchNorm2d,\n",
    "#         n_blocks=3,\n",
    "#         kernel_size=5,\n",
    "#         **cnn_kwargs,\n",
    "#     ),\n",
    "#     y_dim=img_datasets[\"mnist\"].shape[\n",
    "#         0\n",
    "#     ],  # seems to just be the number of output channels\n",
    "#     **model_kwargs,\n",
    "# )\n",
    "\n",
    "# n_params_2d = count_parameters(model_2d())\n",
    "# print(f\"Number Parameters (2D): {n_params_2d:,d}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ConvCNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import skorch\n",
    "# from npf import CNPFLoss\n",
    "# from utils.ntbks_helpers import add_y_dim, get_img_datasets\n",
    "# from utils.train import train_models\n",
    "# from utils.data import cntxt_trgt_collate, get_test_upscale_factor\n",
    "# from npf.utils.datasplit import GridCntxtTrgtGetter, RandomMasker, no_masker\n",
    "\n",
    "# img_datasets, img_test_datasets = get_img_datasets([\"mnist\"])\n",
    "\n",
    "# train_kwargs = dict(\n",
    "#     criterion=CNPFLoss,\n",
    "#     is_retrain=True,\n",
    "#     device=\"cpu\",\n",
    "#     lr=1e-3,\n",
    "#     decay_lr=10,\n",
    "#     seed=123,\n",
    "#     batch_size=32,\n",
    "# )\n",
    "\n",
    "# # 2D\n",
    "# trainers_2d = train_models(\n",
    "#     img_datasets,\n",
    "#     {\"mnist\": model_2d},\n",
    "#     test_datasets=img_test_datasets,\n",
    "#     train_split=skorch.dataset.CVSplit(0.1),  # use 10% of training for valdiation\n",
    "#     iterator_train__collate_fn=get_cntxt_trgt_2d,\n",
    "#     iterator_valid__collate_fn=get_cntxt_trgt_2d,\n",
    "#     max_epochs=50,\n",
    "#     **train_kwargs\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "35fb1e0ce207c8143d1ac09f84e572577d5a384bc00c7057b27c48465068398e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
